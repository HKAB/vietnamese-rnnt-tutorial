# Vietnamese Streaming RNN-Transducer

Welcome! This repo explores training an RNN-T from scratch, using the Whisper encoder as the Audio Encoder. You'll find experiments, a step-by-step tutorial, and a pretrained checkpoint trained on ~6000 hours of Vietnamese speech.

<div align="center">
<img src="./media/Intro.png" alt="Efficient minimum word error rate training of RNN-transducer for end-to-end speech recognition">
<i>Visualization of RNN-T</i>
</div>
<br>

- **Try the demo ğŸ¤–**: [Check out the demo on Huggingface Spaces](https://huggingface.co/spaces/hkab/vietnamese-rnnt-demo)
- **Tutorial (Vietnamese) ğŸ“ƒ**: [Read the detailed blog post](https://hkab.substack.com/p/streaming-rnn-transducer)

## ğŸ—‚ï¸ What's Inside

This repository includes:
- Comprehensive training scripts
- Streaming inference scripts
- ONNX export scripts

ğŸŒŸ We also share  a pre-trained streaming RNN-T model, trained on 6000 hours of Vietnamese audio (1000 labeled hours and 5000 hours labeled by *whisper-large-v3-turbo*). If you want to test the model immediately, checkout `./notebooks/inference.ipynb`.

## ğŸ‹ Docker Setup

To ensure compatibility, we recommend using a version of PyTorch that supports `torch.nn.functional.scaled_dot_product_attention`.

```bash
git clone https://github.com/HKAB/vietnamese-rnnt-tutorial
.git

cd vietnamese-rnnt-tutorial

docker build -t pl25_rnnt .

docker run -itd --gpus all --net host --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 --name YOUR_DOCKER_NAME -v /path/to/local:/wp pl25_rnnt
```

## âš™ï¸ Usage

### ğŸ‹ï¸ Training

Training an RNN-T model is highly GPU-intensive. To train using this repository with `BATCH_SIZE` of 32 and audio lengths of approximately 15 seconds, you will need around **50GB** of vRAM. Here are steps required before training:

1. **Prepare Manifests, Tokenizer**: Create training and validation manifests in NeMo format (there is a sample at `./data/sample.jsonl`) and set their paths to `TRAIN_MANIFEST` and `VAL_MANIFEST`. Then prepare a tokenizer on your text using [sentencepiece](https://github.com/google/sentencepiece).
2. **Prepare Background Noise for Augmentation**: Enhance your training data with background noise from sources like [AudioSet](https://research.google.com/audioset/download.html), [MUSAN](https://www.openslr.org/17/), and [FSDnoisy18k](https://zenodo.org/records/2529934). Set the path to these datasets in `BG_NOISE_PATH`.
3. **Get Pretrained Encoder Weights**: Download the Whisper weights from [here](https://github.com/openai/whisper/blob/main/whisper/__init__.py) to `./weights` and then run `python3 export_encoder.py` to extract the encoder weight for our use. Finally, set the encoder path to `PRETRAINED_ENCODER_WEIGHT`.
4. **Adjust Parameters**: Customize parameters related to the optimizer, scheduler, batch size, number of workers, and more to suit your needs in `constants.py`. 

### âš¡ Inference & ONNX Export

Two notebooks in the `notebooks` folder will guide you through the process.

## ğŸ“Š Performance

For more details on pros and cons of this model, please check out the tutorial.

| Model                   | WER on VIVOS (760 samples) | WER on CM17 (1274 samples) |
|-------------------------|----------------------------|----------------------------|
| RNNT Offline            | 0.1497                     | 0.0657                     |
| RNNT Online             | 0.1521                     | 0.1354                     |
| RNNT Online ONNX (FP32) | 0.1454                     | 0.1237                     |
| RNNT Online ONNX (INT8) | 0.1945                     | 0.2343                     |
| Whisper-small           | 0.2389                     | 0.2956(*)                  |
| Whisper-large-v3-turbo  | **0.094**                  | 0.1963(*)                  |

- Offline mode: We pass the whole audio, no caching. Online mode: We pass audio chunk sequentially, with caching.
- We use [Vinorm](https://github.com/v-nhandt21/Vinorm) for transcript normalization.

(*) Comparing `Whisper-small` and `Whisper-large-v3-turbo` with others on CM17 is not fair since they might not be trained on CM17, but we included them anyway.

## Example

For more examples, please visit [Huggingface Spaces](https://huggingface.co/spaces/hkab/vietnamese-rnnt-demo).

| Audio | Transcript |
|--------|------------|
| <audio controls><source src="./media/Ucraina.mp3" type="audio/mpeg"></audio> | tá»•ng thá»‘ng ukraine volozymy zelensky hÃ´m qua tuyÃªn bá»‘ sáºµn sÃ ng tá»« bá» chá»©c vá»¥ náº¿u Ä‘iá»u Ä‘Ã³ mang láº¡i hÃ²a bÃ¬nh cho ukraine phÃ¡t biá»ƒu táº¡i diá»…n Ä‘Ã n ukraine nÄƒm 2025 tá»•ng thá»‘ng zelensky cho biáº¿t Ã´ng cÃ³ thá»ƒ tá»« chá»©c Ä‘á»ƒ ukraine gia nháº­p nato tá»•ng thá»‘ng zelensk cÅ©ng bÃ y tá» mong muá»‘n tá»•ng thá»‘ng má»¹ donald trump trá»Ÿ thÃ nh Ä‘á»‘i tÃ¡c cá»§a ukraine cÃ²n vá» váº¥n Ä‘á» ná»£ náº§n tá»•ng thá»‘ng zelensky kháº³ng Ä‘á»‹nh lÃ  ukraine tá»« chá»‘i thá»«a nháº­n khoáº£n ná»£ 500 tá»· usd vá»›i má»¹ vÃ  cho ráº±ng khÃ´ng nÃªn coi cÃ¡c khoáº£n viá»‡n trá»£ lÃ  cÃ¡c khoáº£n vay táº¡i hÃ n trung quá»‘c Ä‘Ã£ cÃ³ hÆ¡n 5,5 triá»‡u lÆ°á»£t khÃ¡ch nÆ°á»›c ngoÃ i sá»­ dá»¥ng dá»‹ch vá»¥ váº­n táº£i Ä‘Æ¡n sÃ¡t táº¡i hÃ n quá»‘c trong nÄƒm qua táº­p Ä‘oÃ n Ä‘Æ°á»ng sÃ¡t hÃ n quá»‘c hÃ´m qua cÃ´ng bá»‘ con sá»‘ nÃ y Ä‘Ã£ tÄƒng 61% so vá»›i má»©c lÃ  hÆ¡n 3,4 triá»‡u lÆ°á»£t vÃ o nÄƒm 2023 nguyÃªn nhÃ¢n lÃ  do dá»‹ch vá»¥ bÃ¡n vÃ© cho ngÆ°á»i nÆ°á»›c ngoÃ i Ä‘Æ°á»£c cáº£i thiá»‡n Ä‘á»“ng thá»i má»Ÿ rá»™ng viá»‡c sá»­ dá»¥ng thá»ƒ Ä‘i tÃ u cung cáº¥p dá»‹ch vá»¥ thÃ´ng Ä‘i láº¡i khÃ´ng giá»›i háº¡n trong khu vá»±c thá»§ Ä‘Ã´ seoul táº¡i trung quá»‘c Ä‘á»™i cá»©u há»a vÃ  cá»©u há»™ thanh Ä‘áº£o á»Ÿ tá»‰nh sÆ¡n Ä‘Ã´ng Ä‘Ã£ vá»«a bá»• sung 2 con robot chá»¯a chÃ¡y má»—i con robot náº·ng khoáº£ng 70 cÃ¢n di chuyá»ƒn tá»‘i Ä‘a lÃ  5m trÃªn giÃ¢y hoáº¡t Ä‘á»™ng liÃªn tá»¥c trong vÃ²ng hÆ¡n 3 giá» robot cÃ³ thá»ƒ tá»± Ä‘á»©ng dáº­y vÃ  cÃ¢n báº±ng sau khi ngÃ£ di chuyá»ƒn tá»± do trong mÃ´i trÆ°á»ng nguy hiá»ƒm vá»›i khÃ³i dÃ y vÃ  nhiá»‡t Ä‘á»™ cao cÅ©ng nhÆ° lÃ  khÃ­ Ä‘á»™c robot cÃ³ cáº£m biáº¿n khÃ­ há»‡ thá»‘ng quÃ©t la re nhanh Ä‘á»ƒ phÃ¡t hÃ¬nh quay trá»±c tiáº¿p Ä‘á»ƒ giÃºp chá»‰ huy giÃ¡m sÃ¡t viá»‡c cá»©u náº¡n cá»©u há»™ tá»« xa má»™t chuyáº¿n bay cá»§a hÃ£ng hÃ ng khÃ´ng má»¹ eamon airlines new york Ä‘áº¿n new del sá»± áº¥n Ä‘á»™ Ä‘Ã£ pháº£i chuyá»ƒn hÆ°á»›ng háº¡ cÃ¡nh kháº©n cáº¥p táº¡i chrome cá»§a italy vÃ o ngÃ y hÃ´m qua sau khi nháº­n Ä‘Æ°á»£c thÃ´ng tin Ä‘e dá»a Ä‘Ã¡nh bom chiáº¿c mÃ¡y bay boeing chá»Ÿ 199 hÃ nh khÃ¡ch cÃ¹ng phi hÃ nh Ä‘oÃ n Ä‘Ã£ háº¡ cÃ¡nh an toÃ n vÃ o lÃºc 17h22 giá» rá»i Ä‘á»‹a phÆ°Æ¡ng tá»©c lÃ  tá»‘i qua theo giá» viá»‡t nam táº¥t cáº£ hÃ nh khÃ¡ch Ä‘Ã£ Ä‘Æ°á»£c sÆ¡ tÃ¡n khá»i mÃ¡y bay vÃ  Ä‘Æ°á»£c há»— trá»£ táº¡i sÃ¢n bay chuyáº¿n bay sáº½ tiáº¿p tá»¥c bay Ä‘áº¿n new delhi trong ngÃ y hÃ´m nay |
|||
## ğŸ¤ Contributing

We welcome any contributions! Feel free to open issues or submit pull requests to improve this project.

## âš–ï¸ License

This project is licensed under the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0).